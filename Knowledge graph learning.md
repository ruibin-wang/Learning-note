# Knowledge representation learning


<font size=3> **Definition** </font>

    Knowledge graph embedding is a approach to ***transform Knowledge Graphs*** (nodes, edges and feature vectors) ***into a low dimensional continuous vector*** space that preserves various graph structure information, etc.  



Then this note will present four section about the knowledge representation learning. including representation space, scoring function, encoding models and auxillary information.

***A map of all algorithms[9]:***

<img src=./Pictures/KG_embedding/figure9.png>

---


<font size=3>**1. Representation space (representing entities and relations)**</font></end>

including the  vector, matrix and tensor space, also the  complex vector space, Gaussian space and manifold.

The embedding space should follow three conditions, i.e., differentiability, calculation possibility, and definability of a scoring function

<img src=./Pictures/KG_embedding/figure10.png>

* Point-wise space( Euclidean space):

    As showned in the Figure(a) above.



* Complex vector space:



* Guassian distribution:




* Manifold and group







<font size=3> **2. Scoring function (measuring the plausibility of facts)**</font>




<font size=3> **3.  Encoding models (modeling the semantic interaction of facts)**</font>




<font size=3> **4.  Auxiliary information (utilizing external information)** </font>














